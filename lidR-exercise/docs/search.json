[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Working with Lidar Data in R",
    "section": "",
    "text": "Before You Begin…\n\n\n\nTo successfully work your way through this exercise requires that you have: (1) a working computer with at least four cores, at least 8GB of RAM, at least 2GB free storage (local or network); (2) R installed (the exercise is generated on a machine with R 4.4.1, but that’s not a strict requirement), perhaps along with your IDE of choice (e.g., RStudio); and (3) an internet connection. The first requirement may be somewhat flexible, but data processing may be slow with a less capable computer."
  },
  {
    "objectID": "index.html#a.-what-is-lidar",
    "href": "index.html#a.-what-is-lidar",
    "title": "Working with Lidar Data in R",
    "section": "a. What is lidar?",
    "text": "a. What is lidar?\n\nLight Detection And Ranging\nSometimes abbreviated LiDAR, but let’s be civil and use lidar\nThe general lidar process:\n\nLaser pulses are emitted from a sensor\nThey interact with (reflect off/get absorbed by/transmit through) some object\nSome portion of energy is reflected back to the sensor\nThe timing of this process gives you sensor-object distance\nAdd in sensor position and pulse angle, you’ve got precise x, y, z location of object"
  },
  {
    "objectID": "index.html#b.-types-of-lidar",
    "href": "index.html#b.-types-of-lidar",
    "title": "Working with Lidar Data in R",
    "section": "b. Types of lidar",
    "text": "b. Types of lidar\nThere are two main types of lidar:\n\n\n\n\n\n\nFigure 1: Types of lidar from Salas (2021).\n\n\n\n1. Discrete return lidar\n\nSometimes referred to as “small footprint” lidar\nA pulse’s returned (backscattered/reflected) energy is discretized into modes, representing one or more surfaces the pulse interacted with\nThe result is one or more points in x, y, z space for each pulse\nRepeat this a billion times or so, and you’ve got a point cloud\nMuch more common, particuarly with terrestrial and airborne lidar\nThe focus of this exercise\n\n2. Full waveform lidar\n\nSometimes referred to as “large footprint” lidar\nA pulse’s returned energy is measured as a continuous energetic profile, capturing a more nuanced representation of the surface(s) the pulse ineracted with\nMuch less common, but has gained traction in satellite lidar systems"
  },
  {
    "objectID": "index.html#c.-lidar-platforms",
    "href": "index.html#c.-lidar-platforms",
    "title": "Working with Lidar Data in R",
    "section": "c. Lidar platforms",
    "text": "c. Lidar platforms\nLidar instruments can be mounted on several different platforms, with each serving its own purpose and having its own set of strenghts and weaknesses.\n1. “Terrestrial” (stationary)\n\nI put “terrestrial” in quotes because the next type (mobile) is also technically terrestrial (i.e., ground-based), but the type I’m referring to here is from a stationary terrestrial platform\nCommonly referred to as terrestrial laser scanning (TLS)\nTypically mounted on a tripod\nCommon in engineering and forestry\nYields extreme 3D structural detail, but only at very local scales\nRequires multiple placements and georeferencing, merging of data to avoid occlusion problems\n\n\n\n\n\n\n\nFigure 2: Example of a TLS setup in a forest from earthscope.org.\n\n\n\n2. Mobile\n\nCommonly referred to as mobile laser scanning (MLS)\nCan be handheld, backpack-mounted, vehicle-mounted, etc.\nNewer technology than TLS, but gaining traction in a variety of fields where stationary TLS dominate\nAlso yields extreme 3D structural detail, with slightly lower positional accuracy/precision, and potentially at somewhat broader spatial scales scales\nMitigates occlusion problems as the sensor can move through an environment, around obstacles, etc.\nRelies on simultaneous localization and mapping (SLAM) technology, which builds a point cloud dynamically as the sensor moves, by simultaneously mapping the structure of its surroundings and recognizing its own position within those surroundings\n\n\n\n\n\n\n\nFigure 3: Example of the U’s own Jack Jones wearing a backpack-mounted MLS.\n\n\n\n3. Airborne\n\nCommonly referred to as airborne laser scanning (ALS)\nHistorically almost exclusively mounted on occupied, fixed-wing aircraft (i.e., planes)\nIncreasingly being mounted on unoccupied aerial systems (i.e., drones)\nMuch better source of data for broad-scale mapping than terrestrial or mobile\nBut point densities tend to be considerably lower:\n\n1000+ pts/m2 for terrestrial/mobile\n100 - 500 pts/m2 for UAS lidar\n1 - 20 pts/m2 for traditional ALS\n\nPotentially some canopy occlusion problems in densely-vegetated areas, given the top-down view\n\n\n\n\n\n\n\nFigure 4: ALS schematic from Geospatial Modeling & Visualization at University of Arkansas.\n\n\n\n5. Satellite\n\nRarely referred to as spaceborne/satellite laser scanning (SLS)\nOnly source of global or near-global terrain/vegetation structure\nHowever, existing systems (e.g., ICESat-2, GEDI) collect data in large, discrete footprints, representing a sample of the landscape, rather than a spatially exhaustive scan of an area of interest\n\n\n\n\n\n\n\nFigure 5: The spatial dimensions of GEDI footprint-level satellite lidar data from Oak Ridge National Laboratory.\n\n\n\n\nThe focus of the remainder of this exercise will be on airborne lidar.\n\nThat said, the information provided could be readily applicable to any discrete-return lidar system."
  },
  {
    "objectID": "index.html#d.-lidar-data-formats",
    "href": "index.html#d.-lidar-data-formats",
    "title": "Working with Lidar Data in R",
    "section": "d. Lidar data formats",
    "text": "d. Lidar data formats\nThe most common format for discrete-return lidar point cloud data is a LAZ file (e.g., lidar_data.laz). LAZ files are a lossless compression of LAS files, which was the industry standard lidar data format for a long time. LAS files are still used somewhat, but given the vastly reduced file sizes of LAZ, LAZ has largely replaced LAS.\nThe standard file format for LAZ files can be found in the American Society of Photogrammetry & Remote Sensing’s LAS Specification guide. At their core, point clouds are simply tabular data with x, y, and z coordinates, along with a suite of other (potentially) useful attributes. I’ll highlight the most important ones you’re likely to use below:\n\nX: the x coordinate of a point return (e.g., UTM East)\nY: the y coordinate of a point return (e.g., UTM North)\nZ: the z coordinate of a point return (e.g., elevation)\nIntensity: the amount of energy returned to the sensor for a point return\nReturnNumber: 1st return, 2nd return, etc.\nNumberOfReturns: how many returns were associated with each pulse\nClassification: a numeric classification system for describing what land cover type a return is associated with\n\nThere are many others, but these are the ones you are most likely to use."
  },
  {
    "objectID": "index.html#e.-lidar-data-sources",
    "href": "index.html#e.-lidar-data-sources",
    "title": "Working with Lidar Data in R",
    "section": "e. Lidar data sources",
    "text": "e. Lidar data sources\nIn the US, the two best sources of airborne lidar data are The USGS 3D Elevation Program (3DEP) and OpenTopography. The USGS, of course, has a lengthy history of terrain mapping in the US with its production of topographic maps dating back to the late 19th century. Beginning in 2016, the USGS set about to collect airborne lidar over all of the contiguous US. Less than a decade later, the vast majority of the CONUS has been scanned:\n\nView Lidar Data Availability on The National Map\n\nIt is worth noting that 3DEP has different nominal quality levels (QL):\n\n\n\nTable 1: USGS 3DEP Quality Levels\n\n\n\n\n\n\n\n\n\n\n\nQuality Level\nVertical Accuracy RMSE\nNominal Pulse Spacing\nNominal Pulse Density\n\n\n\n\nQL0\n5 cm\n&lt;= 0.35 m\n&gt;= 8 pts/m2\n\n\nQL1\n10 cm\n&lt;= 0.35 m\n&gt;= 8 pts/m2\n\n\nQL2\n10 cm\n&lt;= 0.71 m\n&gt;= 2 pts/m2\n\n\n\n\n\n\nNote that these are minimum standards – most USGS QL1 data, for example, has considerably higher pulse density than 8 pts/m2. Furthermore, the point density is always higher than this, given that pulses return multiple points (usually 1-4).\nOpenTopography is an NSF-funded facility based at UC San Diego that ingests and serves up all of the USGS 3DEP data in addition to a variety of non-USGS lidar datasets (ALS, TLS, and photogrammetric point clouds). It also offers some basic but potentially very valuable data processing capacities, such as point cloud reprojection and derivation of raster products.\n\nView Lidar Data Availability on OpenTopography\n\nFor what it’s worth, I typically get data directly from the USGS for a few reasons:\n\nThe data are delivered in their native, tiled format (usually 1x1km), which most lidar processing software is well-suited to handle.\nYou can easily interact with the FTP site for data downloading.\nYou can efficiently query The National Map’s API (e.g., using some basic R or Python code) for spatially explicit data requests."
  },
  {
    "objectID": "index.html#f.-lidar-processing-software",
    "href": "index.html#f.-lidar-processing-software",
    "title": "Working with Lidar Data in R",
    "section": "f. Lidar processing software",
    "text": "f. Lidar processing software\nAs with any dataset (especially spatial data), there is a multitude of software options for processing, analyzing, and viewing lidar point cloud data. I won’t even come close to listing them all, but I will point out a few that warrant mentioning.\n1. LAStools\n\nLAStools was one of the first major players in the lidar data processing world. It is one of the best available options for processing large quantities of data very efficiently. Historically it was a purely command line-based software program, and for complex data pipelines (and making LAStools calls from R, Python, etc.) the command line interface is still preferable. However, they have made strides towards making things a little more user friendly with GUIs. To access the full functionality of LAStools does require a license, but several of the tools are free to use.\n\n2. CloudCompare\n\nCloudCompare is an open source software package for viewing, editing, and processing point cloud data. It is less efficient from a processing standpoint than LAStools, but much more user friendly, particularly for tasks requiring interacting directly with the point cloud. In our lab, we use CloudCompare for georeferencing point clouds, as it is by far one of the fastest and most efficient programs for viewing and navigating through point cloud data.\n\n3. Python (pdal)\n\nPDAL is an open source C/C++ library akin to GDAL for efficiently processing point cloud data that has gained considerable momentum recently as a leading tool for processing lidar data. It has a well-supported Python API (package name: pdal) and is built on the concept of building point cloud processing piplines using JSON syntax.\n\n4. R (lidR)\n\nlidR is an R package from Jean-Romain Roussel that encompasses an impressively wide range of functionality. It features (in my opinion) unparalleled flexibility to tailor lidar data processing tasks to suit your needs with intuitive, simple R syntax. It supports parallelization in several ways, making processing tasks relatively efficient, though it is definitely less efficient than LAStools.\n\n\nIn this exercise, we will focus on using lidR in R to analyze lidar data."
  },
  {
    "objectID": "index.html#a.-option-1-download-data-from-the-national-map",
    "href": "index.html#a.-option-1-download-data-from-the-national-map",
    "title": "Working with Lidar Data in R",
    "section": "a. Option 1: Download data from The National Map",
    "text": "a. Option 1: Download data from The National Map\nFor the purposes of this exercise, we will need some lidar data to play with. Please follow the instructions below to download a few tiles of lidar data.\n\n\nVisit The National Map Data Downloader.\nCheck the box next to Elevation Source Data (3DEP) - Lidar, IfSAR.\nMake sure Lidar Point Cloud (LPC) is checked and click Show underneath to reveal the areas of CONUS that have airborne lidar data avaiable for download.\nClick Show Legend to inform your interpretation of the map colors.\nZoom into an area of interest. The exercise will be demonstrating mapping terrain and vegetation in the Wasatch Mountains. You can feel free to zoom into any area of interest, but if there is no terrain or vegetation, then your experience might be a little unexciting.\nUnder Area of Interest on the left panel, select Polygon.\nDraw a polygon on the map around your area of interest and click Search Products.\n\n\n\n\n\n\n\n\nNumber of Lidar Tiles\n\n\n\nKeep in mind that the goal of this exercise is to download four tiles of lidar data. The USGS typically tiles up its lidar data into 1 x 1 km boxes, so you should try (to the best of your ability) to draw a 2 x 2 km polygon. You will likely have to iterate on this several times before you get the scale right. You can feel free to download more tiles, but know that lidar data are quite large in size, and processing more tiles will not only require more storage capacity and memory, but also processing time.\n\n\n\n\n\n\n\n\nNumber of Lidar Projects\n\n\n\nWe also want lidar tiles from the same “project”. The 3DEP program is sort of a hodgepodge of individual lidar data collection campaigns (or, “projects”) that are collected through local, state, and federal partnerships. Unfortunately this makes life a little complicated, as different projects are collected with different specifications, at different times, with different projections, etc. So, for the sake of this exercise, you’re going to want to download four tiles within the same project. You can tell they are a part of the same project based on the file names that are returned after clicking Search Products. They should all have the same prefix and Published Date. As you hover over them, their footprints will be highlighted on the map.\n\n\n\n\nOnce you have identified four adjacent tiles of lidar data from the same project you would like to download, click Download Link (LAZ) next to each of your tiles in the file list.\nStore the files wherever you would like, but you might consider creating a dedicated folder structure for this exercise. One example would be the following:\n\n…\\lidar_exercise (main directory)\n\n…\\lidar_data (lidar directory)\n\n…\\a01_raw (where you should download these “raw” lidar tiles)\n…\\a02_dtm (where you will eventually store DTM raster tiles)\n…\\a03_dsm (where you will eventually store DSM raster tiles)\n…\\a04_hgt (where you will eventually store height-normalized lidar tiles)\n…\\a05_chm (where you will eventually store CHM raster tiles)\n…\\a06_veg (where you will eventually store vegetation structure raster tiles)\n\n…\\other_data (lidar directory)"
  },
  {
    "objectID": "index.html#b.-option-2-download-the-example-data-from-box.",
    "href": "index.html#b.-option-2-download-the-example-data-from-box.",
    "title": "Working with Lidar Data in R",
    "section": "b. Option 2: Download the example data from Box.",
    "text": "b. Option 2: Download the example data from Box.\nIf you don’t want to bother with trying to identify the four, single-project, “perfect” lidar tiles for this exercise, then you can simply download the four example tiles used in this exercise. They cover the base and some of the lower ski runs at Alta Ski Area. You can access them here:\n\nExample Data"
  },
  {
    "objectID": "index.html#a.-summary-information",
    "href": "index.html#a.-summary-information",
    "title": "Working with Lidar Data in R",
    "section": "a. Summary information",
    "text": "a. Summary information\nLet’s do some data exploration:\n\n\nIn your script or the console, type las and press Enter to reveal a summary of its contents.\n\n\n\n\nShow Me the Code!\n# print las summary\nlas\n\n\nclass        : LAS (v1.4 format 6)\nmemory       : 1.6 Gb \nextent       : 445000, 446000, 4492000, 4493000 (xmin, xmax, ymin, ymax)\ncoord. ref.  : NAD83(2011) / UTM zone 12N + NAVD88 height - Geoid12B (metre) \narea         : 1 km²\npoints       : 20.96 million points\ndensity      : 20.96 points/m²\ndensity      : 15.29 pulses/m²\n\n\nThis yields several valuable pieces of information, including the total (uncompressed) memory required to store these data, the spatial extent, the coordinate reference system, the total area covered by the tile, the number of points in the dataset, as well as the point (1st) and pulse (2nd) densities."
  },
  {
    "objectID": "index.html#b.-las-attributes",
    "href": "index.html#b.-las-attributes",
    "title": "Working with Lidar Data in R",
    "section": "b. LAS attributes",
    "text": "b. LAS attributes\nNext, let’s take a look at the attributes contained within the data. Underneath the hood of each LAS object, there is a data.table containing each point’s attributes. To access the table, you can use las@data.\n\n\nRun las@data to reveal the underlying attributes\n\n\n\n\nShow Me the Code!\n# explore the attributes\nlas@data"
  },
  {
    "objectID": "index.html#c.-point-cloud-visualization",
    "href": "index.html#c.-point-cloud-visualization",
    "title": "Working with Lidar Data in R",
    "section": "c. Point cloud visualization",
    "text": "c. Point cloud visualization\nNext, we’ll do some point cloud visualization. Depending on how big your file is and how capable your computer is, this next step may go better or worse. Visualizing point clouds is a fairly computationally (graphically) expensive procedure, given that you’re trying to visualize millions of points in 3D. But, let’s give it a shot! You can visualize point clouds using the plot() function.\n\n\nRun plot(las) to plot the point cloud\n\n\n\n\nShow Me the Code!\n# plot the point cloud out\nplot(las)\n\n\nLike any R plotting function, there are lots of ways to alter your data visualization by manipulating the parameters supplied to plot(). For a full accounting of them, you can enter ?lidR::plot().\n\n\nBy default, the point cloud displays the Z attribute. Try changing this to Intensity to color points by the return intensity. Note that you may also have to change breaks to enhance the contrast to a useful degree.\n\n\n\n\nShow Me the Code!\n# plot point intensity\nplot(las, color = \"Intensity\", breaks = \"quantile\", nbreaks = 50)\n\n\n\n\nPlot intensity again, but with axes and a legend included."
  },
  {
    "objectID": "index.html#d.-a-brief-aside-on-return-intensity",
    "href": "index.html#d.-a-brief-aside-on-return-intensity",
    "title": "Working with Lidar Data in R",
    "section": "d. A brief aside on return intensity",
    "text": "d. A brief aside on return intensity\nLidar return intensity is theoretically a very interesting and useful variable. It measures how much of a laser’s pulse energy is returned to the sensor for a particular return. There are several factors that affect return intensity:\n1. The reflective properties of the surface the pulse interacted with\n\nEnvironmental optics are difficult to concisely describe in a single bullet point, but generally speaking, different surfaces reflect electromagnetic energy differently. A tree’s leaves are green because they absorb more red and blue light and reflect more green light, for example. Most lidar sensors operate in the near-infrared portion of the spectrum (most commonly, 1064 nm). Accordingly, surfaces that reflect more near infrared light are likely to have higher return intensity.\n\n\n\n\n\n\n\nFigure 6: Example reflectance spectra from seos-project.eu.\n\n\n\n2. The geometric properties of the surface\n\nRough surfaces are more likely to produce diffuse backscattering (Lambertian reflectance) of lidar pulse energy in comparison to smooth surfaces, which will feature more specular reflectance. Therefore, smooth surfaces may yield higher return intensities as well.\n\n\n\n\n\n\n\nFigure 7: Lambertian and specular reflectance from oreilly.com.\n\n\n\n3. The pulse angle\n\nLow-angle pulses (i.e., those emitted directly below a sensor) are more likely to have higher return intensity, as the distribution of returned energy is likely to be concentrated in the reflective angle. Conversely, high pulse angles are more likely to yield lower return intensities, as less energy is likely to be reflected back to the sensor. In fact, sometimes a pulse angle threshold is applied to lidar data to remove data above a certain threshold, as it is assumed that high pulse angle data may be more erroneous due to low energy signals.\n\n4. The lidar-surface range\n\nAs laser beams get farther from the sensor, their energy becomes dispersed over a larger area, which effectively reduces the amount of energy, per unit area, that is received by some reflective surface. In turn, a lower amount of energy may be reflected back to the sensor, decreasing return intensity.\n\n\n\n\n\n\n\nFigure 8: Beam divergence from laserworld.com.\n\n\n\n5. Multiple returns\n\nWhen a lidar pulse interacts with multiple surfaces, each return reflects some portion of the pulse’s original energy back to the sensor. Therefore, return intensity may be lower for non-first returns.\n\n\n\n\n\n\n\nFigure 9: Multiple lidar returns from Li et al. (2020).\n\n\n\n6. Sensor specifications\n\nThere is no universal standard for how intensities are measured, quantized, and delivered across sensors. Unlike satellite remote sensing data, which are regularly captured from the same sensor over space and time, airborne lidar from programs such as the USGS 3DEP represent a compilation of many indiviudal airborne campaigns, flown by different vendors, with different sensors. Therefore, comparing intensity values between different lidar projects is very difficult to do.\n\nTaking all of that into consideration, this is why I have said that intensity is a theoretically interesting and useful metric. There are plenty of scientists using intensity to gain some understanding of surface type (in addition to merely surface position), but it’s a challenging pursuit!"
  },
  {
    "objectID": "index.html#e.-noise-in-your-data",
    "href": "index.html#e.-noise-in-your-data",
    "title": "Working with Lidar Data in R",
    "section": "e. Noise in your data",
    "text": "e. Noise in your data\nIf you’re using the point cloud data provided in this exercise, when you plot out the first point cloud, you will see that there are some erroneous points far above and below the true land surface. Unfortunately, noise points like these are not uncommon in discrete-return airborne lidar data. Fortunately, the USGS or the vendors who collected the data will typically run some processes to classify these points as noise, allowing users like us to filter them out. Looking back at the LAS Specification 1.4 (Table 17), we can see that there are two noise classes (7 and 18). Let’s use this as an opportunity to see the distribution of different classes in the Classification attribute of our point cloud data.\n\n\nUse the table() function to summarize the counts of each class in the Classification field of your point cloud data.\n\n\n\n\nShow Me the Code!\n# summarize class totals\ntable(las$Classification)\n\n\n\n       1        2        7       18 \n14915555  6028121    15119       91 \n\n\n\n\n\n\n\n\nAccessing Lidar Attributes\n\n\n\nNote that, when using the dollar sign approach for subsetting, you can access attributes in two different ways. You can do so using the las@data$Classification syntax, or you can simply use las$Classification. However, if you want to subset a column using brackets, you can only do so using the @data approach (e.g., las@data[,\"Classification\"]).\n\n\nIn the example data, it looks like some points have been pre-classified as both 7: Low Point (Noise) and 18: High Noise. Your dataset may not have these, but they should at least have classes 1 (Unclassified) and 2 (Ground). If not, you may reconsider using these data for the remainder of the exercise. It’s also worth noting that, when looking at Table 17 in the LAS Specification 1.4, there are many other classes (e.g., “Low Vegetation”, “Building”, etc.). Seeing this table gives the impression that lidar point clouds are regularly classified into these classes. The reality is that the vast majority of point clouds you download will only have classes 1, 2, 7, and 18 classified. You can certainly perform classifications yourself using several different approaches, but most point clouds are delivered in a somewhat “bare bones” fashion, given the challenge of accurately classifying billions of points.\nAnother attribute of interest that can sometimes be useful for removing bad data is the Withheld_flag. There seems to be a somewhat hazy distinction between noise points and withheld points, and most typically points that are classified as noise (i.e., either 7 or 18) will also be flagged to be withheld. But, there are instances in which they may not nest cleanly.\n\n\nUse the table() function to summarize the number of withheld points.\nUse table() again to cross-tabular withheld points and point classification.\n\n\n\n\nShow Me the Code!\n# tabulate withheld point flags\ntable(las$Withheld_flag)\n\n\n\n   FALSE     TRUE \n20943676    15210 \n\n\nShow Me the Code!\n# cross-tabular withheld flag with classification\ntable(las@data[,c(\"Withheld_flag\", \"Classification\")])\n\n\n             Classification\nWithheld_flag        1        2        7       18\n        FALSE 14915555  6028121        0        0\n        TRUE         0        0    15119       91\n\n\nIn this case, all noise points are also withheld."
  },
  {
    "objectID": "index.html#a.-subsetting-our-point-cloud",
    "href": "index.html#a.-subsetting-our-point-cloud",
    "title": "Working with Lidar Data in R",
    "section": "a. Subsetting our point cloud",
    "text": "a. Subsetting our point cloud\nLet’s begin by subsetting our point cloud to a smaller area. Tree crown delineation can be a fairly computationally expensive process, so working within smaller areas (especially for testing purposes) can be highly beneficial. Furthermore, visually interpreting the outputs is much easier when viewing a local area rather than an entire 1 km2 tile of lidar data.\n\n\nClip your height-normalized lidar data to a 100 x 100 m area in the center of your tile.\n\n\n\n\nShow Me the Code!\n# get spatial subset for clipping\ne &lt;- ext(las_hgt)\nx_center &lt;- mean(e[1:2])\ny_center &lt;- mean(e[3:4])\nx_min &lt;- x_center - 50\nx_max &lt;- x_center + 50\ny_min &lt;- y_center - 50\ny_max &lt;- y_center + 50\n\n# clip height-normalized lidar data\nlas_clip &lt;- clip_rectangle(\n  las_hgt,\n  x_min,\n  y_min,\n  x_max,\n  y_max\n)"
  },
  {
    "objectID": "index.html#b.-detecting-tree-tops",
    "href": "index.html#b.-detecting-tree-tops",
    "title": "Working with Lidar Data in R",
    "section": "b. Detecting tree tops",
    "text": "b. Detecting tree tops\nIn a perfect world, you would know exactly where all of the tree tops are located within an area of interest. If you are working within relatively small field plots, it is conceivable that you could measure tree top point locations on the ground using a high-accuracy GPS. However, that is not a very scalable solution. So we are often left to rely on automatic tree top detection approaches. In lidR, this is accomplished using a moving window approach, using one of two window types:\n1. Fixed-diameter\n\nSimpler but almost certainly less accurate approach that identifies the highest point or pixel within a circular window defined by a fixed diameter. Logically, the diameter of choice should approximately match the typical tree crown diameter. A window that is too large will yield errors of omission (i.e., underdetection/undersegmentation). A window that is too small will yield errors of commission (i.e., overdetection/oversegmentation).\n\n2. Dynamically sized\n\nMore complex approach that requires some understanding of local tree allometry. The window size can vary based on the point/pixel heights. The underlying assumption here is that taller trees tend to have larger crowns, and shorter trees tend to have smaller crowns. By defining a height-to-crown width function, rather than supplying a singular, fixed-window size, you may be able to capture a more accurate depiction of tree tops. This is the approach we will take.\n\nIn lidR, the function for identifying tree tops is locate_trees() and the algorithm you supply to it for parameterizing your moving window is lmf().\n\n\nTake a look at the documentation for each of these functions.\n\n\nWe need a height-to-crown width function to supply to lmf(). We could, of course, make one up. For example, we could assume that trees are generally 5x taller than their crown width. Of course, that depends highly on species and setting. In our region, for example, juniper trees can often be as wide as they are tall (i.e., crown width = 1 x tree height). Conversely, subalpine fir trees can have extremely narrow crowns (i.e., crown width = 0.1 x tree height). Knowing the species composition of your study area may be highly beneficial for generating a locally calibrated local maximum filter.\nTo that end, let’s take a look at TALLO: a global tree allometry and crown architecture database. We will plot out and attempt to model crown width as a function of tree height using species that are known to be in our example study area.\n\n\nNavigate to DB -&gt; Tallo.csv.zip, download the data into your other_dir folder, and extract it.\nRead the data in.\nLimit to just tree species found within the study area (note that this will differ, of course, if you’ve chosen your own study area):\n\nAbies lasiocarpa (subalpine fir)\nAbies concolor (white fir)\nPopulus tremuloides (quaking aspen)\nPseudotsuga menziesii (Douglas-fir)\nPicea engelmannii (Engelmann spruce)\nPicea pungens (blue spruce)\n\nKnowing that several of these species span vast reaches of North America, and may be very structurally different than they are in our study area, further subset the data to an “interior western US” box defined by Latitude 30N - 50N and Longitude 100W - 120W.\nCreate a field called crown_diameter_m the doubles the crown_radius_m, since the lmf() filter relies on a diameter measurement.\nCreate a scatter plot with the remaining data, comparing tree height (x-axis) to tree crown radius (y-axis).\nBuild a linear model that models crown radius as a function of tree height, add the regression line to your plot, and get the model coefficients.\n\n\n\n\nShow Me the Code!\n# read in the tallo data\ndf_tallo &lt;- file.path(other_dir, \"Tallo.csv\") |&gt; read.csv()\n\n# subset to just species of interest\nsp &lt;- c(\n  \"Abies lasiocarpa\", # subalpine fir\n  \"Abies concolor\", # white fir\n  \"Populus tremuloides\", # quaking aspen\n  \"Pseudotsuga menziesii\", # Douglas-fir\n  \"Picea engelmannii\", # Engelmann spruce\n  \"Picea pungens\" # blue spruce\n)\ndf_tallo &lt;- df_tallo[df_tallo$species %in% sp,]\n\n# subset to just dry western us\ndf_tallo &lt;- df_tallo[\n  df_tallo$latitude &gt;= 30 &\n    df_tallo$latitude &lt;= 50 &\n    df_tallo$longitude &lt;= -100 &\n    df_tallo$longitude &gt;= -120,\n]\n\n# remove rows without necessary data\ndf_tallo &lt;- df_tallo[\n  complete.cases(df_tallo[,c(\"height_m\", \"crown_radius_m\")]),\n]\n\n# compute crown diameter\ndf_tallo$crown_diameter_m &lt;- df_tallo$crown_radius_m * 2\n\n# get point colors by density\ndc &lt;- densCols(\n  x = df_tallo$height_m,\n  y = df_tallo$crown_diameter_m,\n  colramp = colorRampPalette(c(\"black\", \"white\"))\n)\ndf_tallo$pt_dens &lt;- col2rgb(dc)[1,] + 1L\ndf_tallo &lt;- df_tallo[order(df_tallo$pt_dens),]\ncols &lt;- viridis(256)\ndf_tallo$col &lt;- cols[df_tallo$pt_dens]\n\n# plot crown radius versus height\nplot(\n  crown_diameter_m ~ height_m,\n  data = df_tallo,\n  pch = 16,\n  col = df_tallo$col,\n  xlab = \"Tree Height (m)\",\n  ylab = \"Crown Radius (m)\",\n  las = 1\n)\n\n# fit linear model\nmod &lt;- lm(crown_diameter_m ~ height_m, data = df_tallo)\nmod_x &lt;- range(df_tallo$height_m)\nmod_y &lt;- predict(mod, newdata = list(height_m = mod_x))\nlines(mod_y ~ mod_x, col = \"hotpink\", lwd = 3)\n\n\n\n\n\n\n\n\n\nShow Me the Code!\n# get linear model summary\nsummary(mod)\n\n\n\nCall:\nlm(formula = crown_diameter_m ~ height_m, data = df_tallo)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.9125 -0.7542 -0.2119  0.6048  7.9881 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 1.196729   0.072554   16.49   &lt;2e-16 ***\nheight_m    0.181155   0.004609   39.30   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.387 on 1485 degrees of freedom\nMultiple R-squared:  0.5099,    Adjusted R-squared:  0.5096 \nF-statistic:  1545 on 1 and 1485 DF,  p-value: &lt; 2.2e-16\n\n\nIt’s definitely not a perfect linear correlation, but the model explains over half of the variance in crown radius, so it’s a much better starting point than a random guess! For the example data, this yields the following local maximum filter function:\n\\[d = 0.2z + 1.2\\]\nwhere \\(d\\) is the crown diameter and \\(z\\) is the tree height, both in meters. We can now translate this into an R function that can be fed to lmf() which, in turn, can be fed to locate_trees() to identify treetops in our study area.\n\n\nTranslate the equation above into a function with a single argument (height) that returns a filter size (i.e., a crown diameter).\nSupply that function to lmf(), while also specifying a minimum tree height of 2 m and a circular filter shape.\nSupply your lmf() function to locate_trees(), along with your clipped point cloud data.\nPlot the point cloud in 3D, making sure to assign the plot to a variable name (e.g., x &lt;- plot(...)).\nAdd the treetop points using the add_treetops3d() function.\n\n\n\n\nShow Me the Code!\n# create lmf function\nf &lt;- function(z) {0.2 * z + 1.2}\nl &lt;- lmf(f, 2, \"circular\")\n\n# identify treetops\nttops &lt;- locate_trees(las_clip, l)\n\n# plot it out in 3D\nx &lt;- plot(las_clip, bg = \"white\", size = 4)\nadd_treetops3d(x, ttops)\n\n\nLooks pretty good!"
  },
  {
    "objectID": "index.html#c.-segmenting-tree-crowns",
    "href": "index.html#c.-segmenting-tree-crowns",
    "title": "Working with Lidar Data in R",
    "section": "c. Segmenting tree crowns",
    "text": "c. Segmenting tree crowns\nNow that we have our treetop seed points, we can feed those into one of several segmentation algorithms. Tree segmentation is the process by which points in a cloud (and/or pixels in a CHM) are assigned to (classified by) the tree to which they most likely belong. It is an imperfect but very useful procedure, especially when tree structural variables (e.g., height, biomass, etc.). One of the reasons it is imperfect is because most segmentation algorithms, including those included in lidR, tend only to be good at segmenting overstory trees – that is, the trees whose crows can be seen from above. Understory trees are likely to be missed or lumped into the segment of tree crowns that overtop them.\nTo see all of the tree segmentation algorithms available in lidR, you can enter ?segment_trees. Feel free to explore them each on your own, but for the sake of this exercise, we will use dalponte2016(). The algorithm is described in Dalponte & Coomes (2016). It is a region-growing algorithm that iteratively associates pixels surrounding the treetop points to each tree according to a few rules defined by the parameters th_tree (minimum tree height), th_seed (region growing parameter 1), th_cr (region growing parameter 2), and max_cr (the maximum crown diameter).\nBefore segmenting trees in the example dataset, however, we are going to have to first generate a new CHM that matches the extent of our clipped point cloud data, since the previous CHM was generated from the full tile of data.\n\n\nUse rasterize_canopy() to generate a 0.25 m-resolution CHM within the extent of your clipped point cloud data with the pitfree() algorithm.\nUse segment_trees() to delineate tree crowns in your clipped lidar data using the dalponte2016() algorithm with default parameters.\nPlot the resulting point cloud in 3D, coloring points by the newly-added field treeID.\n\n\n\n\nShow Me the Code!\n# generate 25cm chm\nchm_trees &lt;- rasterize_canopy(las_clip, 0.25, pitfree())\n\n# segment tree crowns\nlas_trees &lt;- segment_trees(las_clip, dalponte2016(chm_trees, ttops))\n\n# plot in 3d by tree id\nplot(las_trees, color = \"treeID\")\n\n\nAt least in the example dataset, the default segmentation parameters yielded subpar results, with lots of points being left unclassified. This is likely due to the high spatial resolution of the CHM and the fact that max_cr is based on number of pixels. Let’s run again with a much larger max_cr value to hopefully yield an improved delineation.\n\n\nUse segment_trees() again, but set max_cr to 50.\nPlot the resulting point cloud in 3D, coloring points by the newly-added field treeID.\n\n\n\n\nShow Me the Code!\n# generate 25cm chm\nchm_trees &lt;- rasterize_canopy(las_clip, 0.25, pitfree())\n\n# segment tree crowns\nlas_trees &lt;- segment_trees(\n  las_clip, \n  dalponte2016(\n    chm = chm_trees, \n    treetops = ttops,\n    max_cr = 50\n  )\n)\n\n# plot in 3d by tree id\nplot(las_trees, color = \"treeID\")\n\n\nA marked improvement, no doubt. But still clearly imperfect. There are many different approaches one could take to automate and assess the effects of delineation algorithm parameters, but doing so is beyond the scope of this exercise. Feel free to play with the parameters some more if you desire a better delineation. For the sake of the remainder of this exercise, we’ll stick with this delineation, and see what fun things we can do with it."
  },
  {
    "objectID": "index.html#d.-getting-individual-tree-metrics",
    "href": "index.html#d.-getting-individual-tree-metrics",
    "title": "Working with Lidar Data in R",
    "section": "d. Getting individual tree metrics",
    "text": "d. Getting individual tree metrics\nUsing the previously delineated trees, we can derive some useful structural metrics for each tree in your area of interest. This is extremely useful for forest ecology (understanding forest structure over space), fire ecology (understanding fuel structure over space), forestry (quantifying merchantable timber), and even carbon accounting (deriving tree-level carbon estimates through allometry). It could even be used to help create a training database for a machine learning model that attempts to map some structural parameter over large areas – a task that can be very arduous to do manually.\nIn lidR, this is accomplished very simply using the crown_metrics() function. This function returns an sf object, either POINT or POLYGON depending on the user-defined geom of interest. As discussed in a previous section, the *_metrics() functions in lidR allow you to summarize point cloud data within some geometry of interest – in this case, tree crown polygons. For crown_metrics(), you can choose several different geometries, including point(single point for each delineated tree),convex(convex hull around delineated trees),concave(concave hull), andbbox` (bounding box).\n\n\nWrite a function that returns the maximum lidar point z value (height above ground) within each tree crown.\nUse crown_metrics.\nPlot the resulting point cloud in 3D, coloring points by the newly-added field treeID.\n\n\n\n\nShow Me the Code!\n# define a function for summarizing tree structure\nf &lt;- function(z){\n  list(max_z = max(z))\n}\n\n# get tree polygons\ncrowns &lt;- crown_metrics(\n  las = las_trees,\n  func = ~f(Z),\n  geom = \"concave\"\n)\n\n# examine the crowns sf polygon object\ncrowns\n\n\nSimple feature collection with 196 features and 2 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 445450 ymin: 4492450 xmax: 445550 ymax: 4492550\nProjected CRS: NAD83(2011) / UTM zone 12N + NAVD88 height - Geoid12B (metre)\nFirst 10 features:\n   treeID  max_z                       geometry\n1       3  8.384 POLYGON ((445498.3 4492546,...\n2       4 20.811 POLYGON ((445501.4 4492540,...\n3       5 22.397 POLYGON ((445502.6 4492530,...\n4       6 19.933 POLYGON ((445494 4492547, 4...\n5       7 16.701 POLYGON ((445496.9 4492534,...\n6       8 19.754 POLYGON ((445498.7 4492531,...\n7       9 22.936 POLYGON ((445501 4492526, 4...\n8      10 14.102 POLYGON ((445502.7 4492520,...\n9      11 20.290 POLYGON ((445505.5 4492515,...\n10     12 18.496 POLYGON ((445504.8 4492507,...\n\n\nIf you are not familiar with the sf library, it is a world unto itself well worth your exploration time at some later date. For now, we’ll use it in a very basic way – to plot out the tree crowns and their associated heights in 2D. Take a quick look here to learn how to do that: https://r-spatial.github.io/sf/articles/sf5.html.\n\n\nPlot out your tree crowns, with polygons being colored by tree height.\n\n\n\n\nShow Me the Code!\n# plot out \nplot(crowns[\"max_z\"])"
  },
  {
    "objectID": "index.html#a.-reading-the-data-in",
    "href": "index.html#a.-reading-the-data-in",
    "title": "Working with Lidar Data in R",
    "section": "a. Reading the data in",
    "text": "a. Reading the data in\nTo read your point cloud data in as a LAScatalog, you can use the readLAScatalog() function. Like its single-tile counterpart, readLAS(), readLAScatalog() allows you to select a subset of columns or filter to a refined set of points. Unlike its counterpart, you can supply the function’s folder argument with the file directory in which your tiles are stored.\n\n\nRead your four tiles of lidar data in using readLAScatalog(), making sure to filter out noisy and withheld points.\nExamine the resulting object’s properties by entering the variable name into the console.\nPlot the spatial extents of the four tiles using plot().\n\n\n\n\nShow Me the Code!\n# read in the lascatalog data\nctg &lt;- readLAScatalog(raw_dir, filter = \"-drop_class 7 18 -drop_withheld\")\n\n# examine it\nctg\n\n\nclass       : LAScatalog (v1.4 format 6)\nextent      : 445000, 447000, 4492000, 4494000 (xmin, xmax, ymin, ymax)\ncoord. ref. : NAD83(2011) / UTM zone 12N + NAVD88 height - Geoid12B (metre) \narea        : 4 km²\npoints      : 75.22 million points\ndensity     : 18.8 points/m²\ndensity     : 14.5 pulses/m²\nnum. files  : 4 \n\n\nShow Me the Code!\n# plot it out\nplot(ctg)"
  },
  {
    "objectID": "index.html#b.-generate-spatial-index-files",
    "href": "index.html#b.-generate-spatial-index-files",
    "title": "Working with Lidar Data in R",
    "section": "b. Generate spatial index files",
    "text": "b. Generate spatial index files\nOne of the things that makes LAScatalogs so powerful is their inherent awareness of topology. Knowing which tiles, and which points within those tiles, are adjacent to points in neighboring tiles allows for seamless analysis of tiled data. This topology is created through spatial indexing. First introduced by LAStools, the spatial indexing system for LAS/LAZ data involves the creation of LAX files. These are very small files that can be rapidly generated for each LAS/LAZ file in a directory that efficiently store point locations through a quadtree-based position encoding system. You can read in and process LAScatalogs without LAX files, but (as noted in the lidR book) processing efficiency is considerably reduced.\nSo, the question is: how do we generate LAX files? Interestingly, lidR does not have its own indexing function. Instead, it suggests using LAStools to generate these indices. As an alternative, it points to a function in the rlas library, which is a major dependency of lidR, written by the same author, that contains some lower-level functions. Among those functions is writelax(), which allows you to generate a spatial index (LAX) file for a single input LAS/LAZ file.\n\n\nUse rlas::writelax() to generate spatial index files for each of your lidar tiles.\nRead in your LAScatalog again.\n\n\n\n\nShow Me the Code!\n# geneate lax files\nraw_files &lt;- list.files(raw_dir, pattern = \"*.laz$\", full.names = T)\nfor (raw_file in raw_files){\n  rlas::writelax(raw_file)\n}\n\n# read in your lascatalog again\nctg &lt;- readLAScatalog(raw_dir, filter = \"-drop_class 7 18 -drop_withheld\")"
  },
  {
    "objectID": "index.html#c.-lascatalog-processing-options",
    "href": "index.html#c.-lascatalog-processing-options",
    "title": "Working with Lidar Data in R",
    "section": "c. LAScatalog processing options",
    "text": "c. LAScatalog processing options\nThere are several options that you may need to manipulate while working with LAScatalogs. You can see the full list by entering ?\"LAScatalog-class\" into the console. Below I will highlight a few that you are most likely to employ:\n1. chunk_size:\n\nRegardless of the dimensions of your tiles, because of LAScatalogs’ topology, you can actually process “chunks” (i.e., pseudo-tiles) of any dimensions. This is particularly handy if you are working on a computer that does not have a lot of RAM, and/or are working with extremely large point cloud files. In situations like these, you could define smaller chunks than the original tile dimensions, allowing less data to be read in at once during processing.\nThe syntax for setting chunk size is: opt_chunk_size(ctg) &lt;- x, where ctg is your LAScatalog object and x is the length and width of the chunk in the units of the data’s coordinate reference system.\n\n2. buffer:\n\nThis defines the distance around each chunk/tile that is used to pull in points from neighboring chunks/tiles during processing to avoid edge artifacts.\nThe syntax for setting buffer size is: opt_chunk_buffer(ctg) &lt;- x, where ctg is your LAScatalog object and x is the buffer size in the units of the data’s coordinate reference system.\n\n3. laz_compression:\n\nThis is a boolean indicator that defines, for functions that may yield output chunk/tile point cloud files, whether you would like them to be LAS files (FALSE) or LAZ files (TRUE).\nThe syntax for setting buffer size is: opt_laz_compression(ctg) &lt;- x, where ctg is your LAScatalog object and x is either TRUE (or T) or FALSE (or F).\n\n4. output_files:\n\nParticularly when working with large lidar datasets containing many tiles of data, it can be very useful to save intermediate output files that result from applying some function to a LAScatalog. For example, if you are generating a DTM from many chunks/tiles, you may want to store each chunk/tile’s DTM in a file directory. This avoids having to store all of that data in memory, allowing you to subsequently read the tiled DTMs in (as a terra::vrt, for example) from disk.\nThe syntax for setting buffer size is: opt_output_files(ctg) &lt;- x, where ctg is your LAScatalog object and x is a file path template used to name the output files. There are a few template options:\n\n{XLEFT}, {XRIGHT}, {YBOTTOM}, {YTOP}, {ID}, {XCENTER}, {YCENTER}, and {ORIGINALFILENAME}\nFor example, if you wanted to save output files as the same name as the original files in a new folder, you might have code that looks something like this:\n\n\n\n\nShow Me the Code!\n# directory structure\nin_dir &lt;- \"c:/raw_lidar_data\"\nout_dir &lt;- \"c:/dtms\"\n\n# read data in\nctg &lt;- readLAScatalog(in_dir)\n\n# set output files\nopt_output_files(ctg) &lt;- file.path(out_dir, \"{ORIGINALFILENAME}\")\n\n# generate dtms, saving each tile\nrasterize_terrain(ctg)\n\n\nIn the example above, if in_dir had two tiles (“tile_1.laz” and “tile_2.laz”), the successful execution of this script would yield two DTM tiles in out_dir (“tile_1.tif” and “tile_2.tif”).\nNote that there are other LAScatalog processing options that some lidR users might interact with (e.g., stop_early, alignment, drivers), but those are beyond the scope of this high-level overview. If you can familiarize yourself with the syntax and logic of setting a few of these processing options, you can easily figure out how to set others."
  },
  {
    "objectID": "index.html#d.-parallelization-with-future",
    "href": "index.html#d.-parallelization-with-future",
    "title": "Working with Lidar Data in R",
    "section": "d. Parallelization with future",
    "text": "d. Parallelization with future\nAs mentioned earlier, LAScatalogs allow for efficient data processing through parallelization. As described in the documentation when you enter ?\"lidR-parallelism\" into the console, lidR allows for two different types of parallelization:\n1. Algorithm-based parallelization\n\nThis is when individual functions are natively parallelized, meaning that even when processing a single chunk/tile of data, the underlying process can leverage multiple cores to make it execute more quickly.\nSetting the parallelization in this context is accomplished through set_lidr_threads(x), where x is the number of cores you want to use.\n\n2. Chunk-based parallelization\n\nThis is when data from several chunks/tiles is read in using multiple cores and some function is applied to each simultaneously.\nSetting the parallelization in this context is accomplished by setting up a multisession using the future library.\nThe syntax for chunk-based parallelization is as follows:\n\n\n\nShow Me the Code!\n# set up multisession with 5 workers (i.e., employ 5 CPU cores)\nplan(multisession, workers = 5L)\n\n# read in your data\nctg &lt;- readLAScatalog(in_dir)\n\n# run some process\ndtm &lt;- rasterize_terrain(ctg)\n\n# end multisession\nplan(sequential)\n\n\nIn both of these cases, it is important to be cautious about balancing CPU usage with RAM. For example, if you have 10 cores on your machine, you may be tempted to employ all of them in a chunk-based parallelization. But, if each of the chunks contains 5GB of data, this would require 50GB of RAM, as lidR reads entire chunks in at once."
  },
  {
    "objectID": "index.html#e.-generate-some-products-from-your-lascatalog",
    "href": "index.html#e.-generate-some-products-from-your-lascatalog",
    "title": "Working with Lidar Data in R",
    "section": "e. Generate some products from your LAScatalog",
    "text": "e. Generate some products from your LAScatalog\nNow, let’s pull all of this to the test!\n\n\nBegin chunk-based parallelization using the plan() function, setting the number of workers somewhere between 1 and 4. 4 will yield the fastest results, but will require the most RAM. 1 will provide no added benefit processing time-wise to sequential processing.\nRead in your LAScatalog again, filtering noise and withheld points.\nGenerate a 1m-resolution DTM from your LAScatalog, using rasterize_terrain() with thetin()algorithm, making sure to write each of your individual tiles to their own files in thedtm_dirwith their original tile names, and writing the final, mosaicked file (dtm.tif) tolidar_dir`.\nGenerate a 1m-resolution DSM from your LAScatalog, using rasterize_canopy() with the dsmtin() algorithm, making sure to write each of your individual tiles to their own files in the dsm_dir with their original tile names, and writing the final, mosaicked file (dsm.tif) to lidar_dir.\nNormalize heights LAScatalog, using normalize_height() with the tin() algorithm, making sure to set laz_compression to TRUE, writing each of your individual tiles to their own files in the hgt_dir with their original tile names.\nRead in your new, height-normalized data as a separate LAScatalog, still filtering noisy and withheld points.\nGenerate a 1m-resolution CHM from your height-normalized LAScatalog, with rasterize_canopy() using the pitfree() algorithm, making sure to write each of your individual tiles to their own files in the chm_dir with their original tile names, and writing the final, mosaicked file (chm.tif) to lidar_dir.\nGenerate a 10m-resolution canopy cover map from your height-normalized LAScatalog, with pixel_metrics() along with a custom function that calculates canopy cover (number of first returns above 2m / number of all first returns), making sure to write each of your individual tiles to their own files in the veg_dir with their original tile names, and writing the final, mosaicked file (cc.tif) to lidar_dir.\nEnd your parallel session.\nRead each of your study area-wide products (DTM, DSM, CHM, CC) back in as SpatRaster objects.\nPlot out each of them out.\n\n\n\n\n\n\n\n\nA note about overwriting SpatRaster tiles…\n\n\n\nIn the code snippet below, you will see the following line in several places:\nctg@output_options$drivers$SpatRaster$param$overwrite &lt;- T\nThis mess of code is specifically designed to ensure that, if the script is run multiple times, it will not return an error when trying to write individual raster tiles (DTM, DSM, CHM, and CC) to files.\n\n\n\n\nShow Me the Code!\n# begin parallelization\nplan(multisession, workers = 2L)\n\n# read in lascatalog\nctg &lt;- readLAScatalog(raw_dir, filter = \"-drop_class 7 18 -drop_withheld\")\n\n# generate dtm\nopt_output_files(ctg) &lt;- file.path(dtm_dir, \"{ORIGINALFILENAME}\")\nctg@output_options$drivers$SpatRaster$param$overwrite &lt;- T\ndtm &lt;- rasterize_terrain(ctg)\n\n\n\n\n\n\n\n\n\nChunk 1 of 4 (25%): state ✓\nChunk 2 of 4 (50%): state ✓\nChunk 3 of 4 (75%): state ✓\nChunk 4 of 4 (100%): state ✓\n\n\nShow Me the Code!\nwriteRaster(dtm, file.path(lidar_dir, \"dtm.tif\"), overwrite = T)\n\n# generate dsm\nopt_output_files(ctg) &lt;- file.path(dsm_dir, \"{ORIGINALFILENAME}\")\nctg@output_options$drivers$SpatRaster$param$overwrite &lt;- T\ndsm &lt;- rasterize_canopy(ctg, algorithm = dsmtin())\n\n\n\n\n\n\n\n\n\nChunk 2 of 4 (25%): state ✓\nChunk 1 of 4 (50%): state ✓\nChunk 3 of 4 (75%): state ✓\nChunk 4 of 4 (100%): state ✓\n\n\nShow Me the Code!\nwriteRaster(dsm, file.path(lidar_dir, \"dsm.tif\"), overwrite = T)\n\n# normalize heights\nopt_output_files(ctg) &lt;- file.path(hgt_dir, \"{ORIGINALFILENAME}\")\nopt_laz_compression(ctg) &lt;- T\nnormalize_height(ctg, tin())\n\n\n\n\n\n\n\n\n\nChunk 2 of 4 (25%): state ✓\nChunk 1 of 4 (50%): state ✓\nChunk 3 of 4 (75%): state ✓\nChunk 4 of 4 (100%): state ✓\n\n\nclass       : LAScatalog (v1.4 format 6)\nextent      : 445000, 447000, 4492000, 4494000 (xmin, xmax, ymin, ymax)\ncoord. ref. : NAD83(2011) / UTM zone 12N + NAVD88 height - Geoid12B (metre) \narea        : 4 km²\npoints      : 75.16 million points\ndensity     : 18.8 points/m²\ndensity     : 14.5 pulses/m²\nnum. files  : 4 \n\n\nShow Me the Code!\n# generate canopy height model\nctg_hgt &lt;- readLAScatalog(hgt_dir, filter = \"-drop_class 7 18 -drop_withheld\")\nopt_output_files(ctg_hgt) &lt;- file.path(chm_dir, \"{ORIGINALFILENAME}\")\nctg_hgt@output_options$drivers$SpatRaster$param$overwrite &lt;- T\nchm &lt;- rasterize_canopy(ctg_hgt, algorithm = pitfree())\n\n\n\n\n\n\n\n\n\nChunk 2 of 4 (25%): state ✓\nChunk 1 of 4 (50%): state ✓\nChunk 3 of 4 (75%): state ✓\nChunk 4 of 4 (100%): state ✓\n\n\nShow Me the Code!\nwriteRaster(chm, file.path(lidar_dir, \"chm.tif\"), overwrite = T)\n\n# generate canopy cover raster\nf &lt;- function(z, r){\n  z &lt;- z[r == 1]\n  numer &lt;- length(z[z &gt;= 2])\n  denom &lt;- length(z)\n  cc &lt;- numer / denom\n  l &lt;- list(cc = cc)\n  return(l)\n}\nopt_output_files(ctg_hgt) &lt;- file.path(veg_dir, \"{ORIGINALFILENAME}\")\nctg_hgt@output_options$drivers$SpatRaster$param$overwrite &lt;- T\ncc &lt;- pixel_metrics(ctg_hgt, ~f(Z, ReturnNumber), 10)\n\n\n\n\n\n\n\n\n\nChunk 2 of 4 (25%): state ✓\nChunk 1 of 4 (50%): state ✓\nChunk 3 of 4 (75%): state ✓\nChunk 4 of 4 (100%): state ✓\n\n\nShow Me the Code!\nwriteRaster(cc, file.path(lidar_dir, \"cc.tif\"), overwrite = T)\n\n# end parallelization\nplan(sequential)\n\n# read them back in\ndtm &lt;- file.path(lidar_dir, \"dtm.tif\") |&gt; rast()\ndsm &lt;- file.path(lidar_dir, \"dsm.tif\") |&gt; rast()\nchm &lt;- file.path(lidar_dir, \"chm.tif\") |&gt; rast()\ncc &lt;- file.path(lidar_dir, \"cc.tif\") |&gt; rast()\n\n# plot outputs\nplot(dtm)\n\n\n\n\n\n\n\n\n\nShow Me the Code!\nplot(dsm)\n\n\n\n\n\n\n\n\n\nShow Me the Code!\nplot(chm)\n\n\n\n\n\n\n\n\n\nShow Me the Code!\nplot(cc)"
  }
]